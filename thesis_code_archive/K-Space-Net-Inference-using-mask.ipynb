{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "825916c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from positional_encodings.torch_encodings import PositionalEncoding1D, PositionalEncoding2D, PositionalEncoding3D, Summer\n",
    "import numpy as np\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.io import savemat, loadmat\n",
    "import random\n",
    "random.seed(2)\n",
    "torch.manual_seed(2)\n",
    "torch.cuda.manual_seed(2)\n",
    "np.random.seed(2)\n",
    "\n",
    "mdict = loadmat(\"PosEncode.mat\")\n",
    "## TODO: this cell should be saves seperatly and the result could be loaded at the initially\n",
    "PosEncoding = mdict[\"PositionalEncoding\"]\n",
    "\n",
    "## Load Postional Condition, Repeat it based on batch_size and Convert it Torch.Tensor\n",
    "# PosEncoding = scipy.loatmat()\n",
    "PosEncoding = torch.tensor(PosEncoding)\n",
    "# PosEncoding = PosEncoding[np.newaxis,:,:,:].repeat(batch_size,1,1,1)\n",
    "print(PosEncoding.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab1396ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import scipy.fftpack\n",
    "import numpy as np\n",
    "from torch.utils.data import Dataset, DataLoader, TensorDataset\n",
    "from torchvision import transforms, utils\n",
    "import torchvision\n",
    "import torch\n",
    "import glob\n",
    "from medpy.io import load, save\n",
    "import sys\n",
    "from scipy.io import savemat\n",
    "\n",
    "save_to_dir = 'J:/Anvari/MsThesis/K-Space-Net_2sliceApart/T2/40_Percent/Gaussian/'\n",
    "# save_to_dir = 'J:/Anvari/MsThesis/K-Space-Net_2sliceApart/T2/half_slices/'\n",
    "model_dir = 'J:/Anvari/MsThesis/K-Space-Net_2sliceApart/T2_model/'\n",
    "model_dir2 = 'J:/Anvari/MsThesis/K-Space-Net_2sliceApart/T1_model/'\n",
    "LINE_CLEAR = '\\x1b[2K' # <-- ANSI sequence\n",
    "train_root = 'J:\\\\Anvari\\\\proccessed_data_257\\\\train\\\\'\n",
    "validation_root = 'J:\\\\Anvari\\\\proccessed_data_257_2sliceApart\\\\validation\\\\'\n",
    "test_root = 'J:\\\\Anvari\\\\proccessed_data_257_2sliceApart\\\\test\\\\'\n",
    "\n",
    "transform_2015 = transforms.Compose([transforms.ConvertImageDtype(torch.float),\n",
    "                                     transforms.Normalize(0.5, 0.5, 0.5)])\n",
    "\n",
    "\n",
    "def imshow(img, batch_size, name, cmap):\n",
    "    if torch.is_tensor(img):\n",
    "        npimg = img.numpy()\n",
    "    else:\n",
    "        npimg = img\n",
    "    if npimg.ndim > 2:\n",
    "        npimg = np.transpose(npimg, (1, 2, 0))\n",
    "    plt.figure(figsize=(7, 4))\n",
    "    \n",
    "    if cmap != 'gray':\n",
    "        # c = 1 / np.log(1 + np.max(npimg[:,:,0]))\n",
    "        # image = c * (np.log(npimg[:,:,0] + 1))\n",
    "        if npimg.ndim > 2:\n",
    "            image = npimg[:,:,0]\n",
    "    else:\n",
    "        if npimg.ndim > 2:\n",
    "            image = npimg[:,:,0]\n",
    "        else:\n",
    "            image = npimg\n",
    "\n",
    "    if cmap != 'gray':\n",
    "        image[-1,-1] = 0.1\n",
    "        image[-2,-1] = 0\n",
    "        plt.imshow(image,interpolation = 'none',cmap=cmap,vmin=0,vmax=0.1)\n",
    "        plt.colorbar(orientation=\"horizontal\")\n",
    "        plt.axis('off')\n",
    "        plt.savefig(save_to_dir+'{}_01.png'.format(name), format='png', dpi=600)\n",
    "        plt.figure(figsize=(7, 4))\n",
    "        image[-1,-1] = 1\n",
    "        image[-2,-1] = 0\n",
    "        plt.imshow(image,interpolation = 'none',cmap=cmap,vmin=0,vmax=1)\n",
    "        plt.colorbar(orientation=\"horizontal\")\n",
    "        plt.axis('off')\n",
    "        plt.savefig(save_to_dir+'{}_10.png'.format(name), format='png', dpi=600)\n",
    "    else:\n",
    "        image[-1,-1] = 1\n",
    "        image[-2,-1] = 0\n",
    "        plt.imshow(image,interpolation = 'none',cmap=cmap,vmin=0,vmax=1)\n",
    "        plt.axis('off')\n",
    "        plt.savefig(save_to_dir+'{}.png'.format(name), format='png', dpi=600)\n",
    "\n",
    "def load_mask(mask_name):\n",
    "    dir = 'C:\\\\Users\\\\mehrdad\\\\MS_projects\\\\mask\\\\Build mask'\n",
    "    matfile = scipy.io.loadmat(dir + '\\\\{}.mat'.format(mask_name)) \n",
    "    print(type(matfile))\n",
    "    print(matfile.keys())\n",
    "    # print(matfile.get(\"__header__\"))\n",
    "    mask = np.zeros((6,257,257))\n",
    "    mask_P = matfile.get('PrimaryMask')\n",
    "    mask_S = matfile.get('SecondaryMask')\n",
    "    mask_P = np.logical_or(mask_P,np.flip(mask_P))\n",
    "    mask_S = np.logical_or(mask_S,np.flip(mask_S))\n",
    "    mask[0,:,:]=mask_S\n",
    "    mask[1,:,:]=mask_P\n",
    "    mask[2,:,:]=mask_S\n",
    "    mask[3,:,:]=mask_P\n",
    "    mask[4,:,:]=mask_S\n",
    "    mask[5,:,:]=mask_P\n",
    "    # mask[0,:,:]=1\n",
    "    # mask[1,:,:]=1\n",
    "    # mask[2,:,:]=1\n",
    "    # mask[3,:,:]=1\n",
    "    # mask[4,:,:]=0\n",
    "    # mask[5,:,:]=1\n",
    "    # print(mask.sum() / (256 * 256))\n",
    "    print(mask.shape)\n",
    "    print(mask.dtype)\n",
    "    print(type(mask))\n",
    "    plt.imshow(mask_P)\n",
    "    plt.title(mask_name)\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "    plt.imshow(mask_S)\n",
    "    plt.title(mask_name)\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "    plt.imshow(np.logical_or(mask_P,mask_S))\n",
    "    plt.title(mask_name)\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "    imshow(mask_P, 10, 'primary', cmap='gray')\n",
    "    imshow(mask_S, 10, 'secodary', cmap='gray')\n",
    "    imshow(np.logical_or(mask_P,mask_S), 10, 'Union', cmap='gray')\n",
    "\n",
    "    return mask\n",
    "\n",
    "# mask = load_mask('Deterministic1DMask_40_257')\n",
    "mask = load_mask('GaussianDistribution1DMask_40_257')\n",
    "# mask = load_mask('UniformDistribution1DMask_10_257')\n",
    "                \n",
    "mask_c = 1 - mask\n",
    "\n",
    "# def cal_fft_for_all_channels(x):\n",
    "#     fft = np.zeros_like(x).astype('complex128')\n",
    "#     for i in range(6):\n",
    "#         fft[i, :, :] = scipy.fftpack.fft2(x[i, :, :])\n",
    "#         fft[i, :, :] = scipy.fftpack.fftshift(fft[i, :, :])\n",
    "#     return np.real(fft).astype('float32'),np.imag(fft).astype('float32')\n",
    "\n",
    "def cal_fft_for_all_channels(x):\n",
    "    # fft = torch.zernp.zeros_like(x).astype('complex128'), dtype=torch.complex64\n",
    "    fft = torch.zeros_like(x,dtype=torch.complex64)\n",
    "    fft = torch.fft.fft2(x)\n",
    "    fft = torch.fft.fftshift(fft,dim=(1,2))\n",
    "    # for i in range(6):\n",
    "    #     fft[i, :, :] = scipy.fftpack.fft2(x[i, :, :])\n",
    "    #     fft[i, :, :] = scipy.fftpack.fftshift(fft[i, :, :])\n",
    "    return torch.real(fft).to(torch.float32) ,torch.imag(fft).to(torch.float32)\n",
    "\n",
    "def to_bad_img(x, mask):\n",
    "    x = (x + 1.) / 2.\n",
    "    \n",
    "#     print(f\"mask shape is:{x.shape}\")\n",
    "    for i in range(6):\n",
    "        fft = scipy.fftpack.fft2(x[i, :, :])\n",
    "        fft = scipy.fftpack.fftshift(fft)\n",
    "        fft = fft * mask[i,:,:]\n",
    "        fft = scipy.fftpack.ifftshift(fft)\n",
    "        x[i, :, :] = scipy.fftpack.ifft2(fft)\n",
    "        x[i, :, :] = np.abs(x[i, :, :])\n",
    "        x[i, :, :] = x[i, :, :] * 2 - 1\n",
    "    return x\n",
    "\n",
    "class Brats2013_2D(Dataset):\n",
    "    def __init__(self, root, transform=transform_2015 , PE = PosEncoding):\n",
    "        self.img_dir = root\n",
    "        self.positionalEncoding = PE\n",
    "        self.transform = transform\n",
    "        file_list = glob.glob(root + \"*.mha\")\n",
    "        self.data = []\n",
    "        for file_path in file_list:\n",
    "            layer_name = file_path.split(\"\\\\\")[-1].split(\".\")[-2].split(\"_\")[-1]\n",
    "            self.data.append([file_path, int(layer_name)])\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path, LayerNum = self.data[idx]\n",
    "        image, image_header = load(img_path)\n",
    "        image = torch.tensor(image).cuda().to(torch.float32)\n",
    "        image_fft_r,image_fft_i = cal_fft_for_all_channels(image)\n",
    "        # image_fft_r = torch.tensor(image_fft_r)\n",
    "        # image_fft_i = torch.tensor(image_fft_i)\n",
    "        # image = torch.tensor(image)\n",
    "        return image_fft_r, image_fft_i, image, torch.tensor(LayerNum), torch.tensor(self.positionalEncoding)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def imsave(img,epoch,i,name,batch_size):\n",
    "    img_slices = np.zeros((6*batch_size,240,240))\n",
    "    for j in range(batch_size*6):\n",
    "        img_slices[j,:,:] = img[int(j//6),int(j%6),:,:]\n",
    "    save(img_slices,save_to_dir+f'{name}_{epoch}_{i}.mha')\n",
    "\n",
    "batch_size = 10\n",
    "\n",
    "dataset = Brats2013_2D(root=train_root , PE = PosEncoding)\n",
    "dataset_val = Brats2013_2D(root=validation_root, PE=PosEncoding)\n",
    "dataset_test = Brats2013_2D(root=test_root, PE=PosEncoding)\n",
    "dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "dataloader_val = DataLoader(dataset_val, batch_size=batch_size, shuffle=True)\n",
    "dataloader_test = DataLoader(dataset_test, batch_size=batch_size, shuffle=True)\n",
    "img_fft_r, img_fft_i, img ,layer , PosEn = next(iter(dataloader))\n",
    "print(type(img_fft_r))\n",
    "print(img_fft_r.dtype)\n",
    "print('img_fft_r shape = {}'.format(img_fft_r.shape))\n",
    "print('layer = {}'.format(layer.shape))\n",
    "print('PosEn shape = {}'.format(PosEn.shape))\n",
    "plt.imshow(img_fft_r[0,0,:,:].cpu())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "801f7301",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "import math\n",
    "class SinusoidalPositionEmbeddings(nn.Module):\n",
    "    def __init__(self, dim):\n",
    "        super().__init__()\n",
    "        self.dim = dim\n",
    "\n",
    "    def forward(self, layer):\n",
    "        device = layer.device\n",
    "        half_dim = self.dim // 2\n",
    "        embeddings = math.log(10000) / (half_dim - 1)\n",
    "        embeddings = torch.exp(torch.arange(half_dim, device=device) * -embeddings)\n",
    "        embeddings = layer[:, None] * embeddings[None, :]\n",
    "        embeddings = torch.cat((embeddings.sin(), embeddings.cos()), dim=-1)\n",
    "        return embeddings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12262ca2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "import torch\n",
    "from torch import nn\n",
    "import numpy as np\n",
    "from torchsummary import summary\n",
    "from torchvision import models\n",
    "from einops import rearrange\n",
    "if torch.cuda.is_available():\n",
    "    print('it works')\n",
    "else:\n",
    "    print('it doesnt work')\n",
    "device = torch.device(\"cuda:0\" if (torch.cuda.is_available() and 1 > 0) else \"cpu\")\n",
    "print('device is {}'.format(device))\n",
    "\n",
    "\n",
    "class KspaceNetT1(nn.Module):\n",
    "    def __init__(self,ngpu):\n",
    "        super(KspaceNetT1, self).__init__()\n",
    "        self.df_dim = 32     ## TODO: normalizing the input k-space\n",
    "        self.posEn_dim = 34\n",
    "        self.layEn_dim = 32\n",
    "        self.conv1 = nn.Conv2d(10 + self.posEn_dim + self.layEn_dim , 4*self.df_dim, (1, 1), padding=(0, 0))\n",
    "        self.conv2 = nn.Conv2d(4*self.df_dim, 2*self.df_dim, (1, 1), padding=(0, 0))\n",
    "        self.conv3 = nn.Conv2d(2*self.df_dim, 1*self.df_dim, (1, 1), padding=(0, 0))\n",
    "        self.conv4 = nn.Conv2d(1*self.df_dim, 2, (1, 1), padding=(0, 0))\n",
    "\n",
    "        self.batch1 = nn.BatchNorm2d(4 * self.df_dim)\n",
    "        self.batch2 = nn.BatchNorm2d(2 * self.df_dim)\n",
    "        self.batch3 = nn.BatchNorm2d(1 * self.df_dim)\n",
    "\n",
    "        ## TODO: an MLP model for Layer encoding \n",
    "        self.layer_mlp = nn.Sequential(\n",
    "            SinusoidalPositionEmbeddings(self.layEn_dim),\n",
    "            nn.Linear(self.layEn_dim, self.layEn_dim),\n",
    "            nn.GELU(),\n",
    "            nn.Linear(self.layEn_dim, self.layEn_dim),\n",
    "        )\n",
    "        \n",
    "        self.layer_mlp2 = nn.Sequential(\n",
    "            SinusoidalPositionEmbeddings(self.layEn_dim),\n",
    "            nn.Linear(self.layEn_dim, self.layEn_dim),\n",
    "            nn.GELU(),\n",
    "            nn.Linear(self.layEn_dim, 2*self.posEn_dim),\n",
    "        )\n",
    "        \n",
    "        self.layer_mlp3 = nn.Sequential(\n",
    "            SinusoidalPositionEmbeddings(self.layEn_dim),\n",
    "            nn.Linear(self.layEn_dim, self.layEn_dim),\n",
    "            nn.GELU(),\n",
    "            nn.Linear(self.layEn_dim, 10),\n",
    "        )\n",
    "        \n",
    "        self.convLEPEforX = nn.Conv2d(self.posEn_dim + 10, 10*2, (1, 1), padding=(0, 0))\n",
    "        \n",
    "    def forward(self, x, PE, LE):\n",
    "\n",
    "        layerEmbeddingLatent = self.layer_mlp(LE)\n",
    "        \n",
    "        LEchs = rearrange(layerEmbeddingLatent, \"b c -> b c 1 1\")\n",
    "        LEchs = LEchs.repeat(1,1,257,257) ## TODO: check if scale and shifting X using LEchs is any better\n",
    "        ## TODO: Check if scale and shifting PE using LEch is any better\n",
    "        LEforPE = self.layer_mlp2(LE)\n",
    "        LEforPE2 = rearrange(LEforPE, \"b c -> b c 1 1\")\n",
    "        scale_shift = LEforPE2.chunk(2, dim=1)\n",
    "        scale, shift = scale_shift\n",
    "        PE = PE * (scale + 1) + shift\n",
    "        ## TODO: Check if scale and shiftinf PE using LEch and concat it to X while the X itself is scaled and shifted by scaled and shifted PE \n",
    "        LEforX = self.layer_mlp3(LE)\n",
    "        LEforX2 = rearrange(LEforX, \"b c -> b c 1 1\")\n",
    "        LEforX2 = LEforX2.repeat(1,1,257,257)\n",
    "        LEPEforX = torch.concat((PE, LEforX2),dim=1)\n",
    "        LEPEforX2 = self.convLEPEforX(LEPEforX)\n",
    "        scale_shift = LEPEforX2.chunk(2, dim=1)\n",
    "        scale, shift = scale_shift\n",
    "        x = x * (scale + 1) + shift\n",
    "        ## TODO: Concatinate input (x), Positional Encoding (PE), Layer Encoding (LE)\n",
    "        \n",
    "        \n",
    "        x = torch.concat((x, PE, LEchs),dim=1)\n",
    "\n",
    "        x = self.conv1(x)\n",
    "        x = nn.LeakyReLU(0.2)(x)\n",
    "        x = self.batch1(x)\n",
    "\n",
    "        x = self.conv2(x)\n",
    "        x = nn.LeakyReLU(0.2)(x)\n",
    "        x = self.batch2(x)\n",
    "\n",
    "        x = self.conv3(x)\n",
    "        x = nn.LeakyReLU(0.2)(x)\n",
    "        x = self.batch3(x)\n",
    "\n",
    "        x = self.conv4(x)\n",
    "#         x = nn.Tanh()(x)\n",
    "        \n",
    "        return x\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f488c98d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import torch.optim as optim\n",
    "import torchvision.utils as vutils\n",
    "from torchmetrics import StructuralSimilarityIndexMeasure, PeakSignalNoiseRatio\n",
    "import os\n",
    "import json\n",
    "\n",
    "\n",
    "ngpu = 1\n",
    "lr = 0.001\n",
    "lr_decay = 0.5\n",
    "decay_every = 5\n",
    "n_epoch = 9999\n",
    "beta1 = 0.5\n",
    "batch_size = 10\n",
    "workers = 1\n",
    "\n",
    "## check if cuda is available or not?\n",
    "if torch.cuda.is_available():\n",
    "    print('CUDA is Available!')\n",
    "else:\n",
    "    print('CUDA is NOT Available!')\n",
    "device = torch.device(\"cuda:0\" if (torch.cuda.is_available() and ngpu > 0) else \"cpu\")\n",
    "print('device is {}'.format(device))\n",
    "\n",
    "## Empety torch cuda cache\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "## Define the model\n",
    "model = KspaceNetT1(ngpu).to(device)\n",
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print(count_parameters(model))\n",
    "\n",
    "\n",
    "## Define optimizer\n",
    "print('Setup Adam optimizers for D')\n",
    "optimizer = optim.Adam(model.parameters(), lr=lr, betas=(beta1, 0.999))\n",
    "scheduler = optim.lr_scheduler.ExponentialLR(optimizer, gamma=0.5)\n",
    "\n",
    "## Define Loss\n",
    "criterion = torch.nn.MSELoss()\n",
    "\n",
    "## Define Metrics\n",
    "psnr = PeakSignalNoiseRatio()\n",
    "ssim = StructuralSimilarityIndexMeasure(data_range=1.0)\n",
    "\n",
    "## Load the model if exists, pre-trained model\n",
    "\n",
    "# if  os.path.isfile(model_dir + 'modelt2.pt'):\n",
    "#     model = torch.load(model_dir + 'modelt2.pt')\n",
    "    \n",
    "# model.eval()\n",
    "\n",
    "if  os.path.isfile(model_dir + 'modelt1.pt'):\n",
    "    model = torch.load(model_dir + 'modelt1.pt')\n",
    "    \n",
    "model.eval()\n",
    "    \n",
    "    \n",
    "print(f'scheduler : {scheduler.get_last_lr()}')\n",
    "\n",
    "\n",
    "\n",
    "## Define some List to Keep track of the Learning \n",
    "\n",
    "#  Validation Data\n",
    "PSNR_V = []\n",
    "SSIM_V = []\n",
    "MSE_IMG_V = []\n",
    "\n",
    "\n",
    "PSNR_V2 = []\n",
    "SSIM_V2 = []\n",
    "MSE_IMG_V2 = []\n",
    "\n",
    "\n",
    "mask = torch.tensor(mask).to(device)\n",
    "mask_c = torch.tensor(mask_c).to(device)\n",
    "\n",
    "\n",
    "t_p = 4\n",
    "t_c = 1\n",
    "# mask[t_p,:,:] = 0\n",
    "# mask[t_c,:,:] = 1\n",
    "# mask[0,:,:] = 1\n",
    "# mask[2,:,:] = 1\n",
    "# mask[3,:,:] = 1\n",
    "# mask[5,:,:] = 1\n",
    "## show the predited image\n",
    "with torch.no_grad():\n",
    "            \n",
    "        PSNR_Vt = 0\n",
    "        SSIM_Vt = 0\n",
    "        MSE_FFT_Vt = 0\n",
    "        MSE_IMG_Vt = 0\n",
    "        MSE_RealEven_Vt = 0\n",
    "        MSE_ImagOdd_Vt  = 0\n",
    "        \n",
    "        PSNR_Vt2 = 0\n",
    "        SSIM_Vt2 = 0\n",
    "        MSE_FFT_Vt2 = 0\n",
    "        MSE_IMG_Vt2 = 0\n",
    "        MSE_RealEven_Vt2 = 0\n",
    "        MSE_ImagOdd_Vt2  = 0\n",
    "\n",
    "        print('Calculating loss and metrics for Validation dataset ... ')\n",
    "        for l, data_val in tqdm(enumerate(dataloader_test, 0)):\n",
    "            # load one batch of data\n",
    "\n",
    "            image_fft_r, image_fft_i, image, LayerNum, PosEncoding = data_val\n",
    "            for i in range(6):\n",
    "                image_fft_r[:,i,:,:] = image_fft_r[:,i,:,:].to(device) * mask[i,:,:]\n",
    "                image_fft_i[:,i,:,:] = image_fft_i[:,i,:,:].to(device) * mask[i,:,:]\n",
    "\n",
    "            if t_p == 4:  \n",
    "                ListConChIdxs = [0,t_c,2,3,5] ## index 1 is the T1 middle layer that should be predicted\n",
    "            if t_p == 1:\n",
    "                ListConChIdxs = [0,2,3,t_c,5] ## index 1 is the T1 middle layer that should be predicted\n",
    "\n",
    "            image_fft_in = torch.concat((image_fft_r[:,ListConChIdxs,:,:],image_fft_i[:,ListConChIdxs,:,:]), dim = 1).to(device)\n",
    "            image_fft_out = torch.concat((image_fft_r[:,t_p,:,:][:,np.newaxis,:,:],image_fft_i[:,t_p,:,:][:,np.newaxis,:,:]), dim = 1).to(device)\n",
    "            \n",
    "            PosEncoding = PosEncoding.to(device)\n",
    "            ## Inference\n",
    "            Predition = model(image_fft_in.float(),PosEncoding.float(),LayerNum.to(device))\n",
    "            \n",
    "            # correct values of estimated image using true ones\n",
    "            Predition[:,0,:,:] = Predition[:,0,:,:] * mask_c[t_p,:,:] + image_fft_r[:,t_p,:,:].to(device) * mask[t_p,:,:]\n",
    "            Predition[:,1,:,:] = Predition[:,1,:,:] * mask_c[t_p,:,:] + image_fft_i[:,t_p,:,:].to(device) * mask[t_p,:,:]\n",
    "            \n",
    "            ## Calculate the Loss term\n",
    "            complexPrediction  = Predition[:,0,:,:][:,np.newaxis,:,:]+Predition[:,1,:,:][:,np.newaxis,:,:]*1j\n",
    "            complexPrediction = torch.fft.ifftshift(complexPrediction,dim=(2,3))\n",
    "            image_Predition = torch.fft.ifft2(complexPrediction)\n",
    "            image_Predition = torch.real(torch.tensor(image_Predition).float())\n",
    "            for k in range(image_Predition.shape[0]):\n",
    "                nume = torch.sqrt(torch.sum(torch.square((image_Predition[k,:,:,:][np.newaxis,:,:,:]-image[k,t_p,:,:][np.newaxis,np.newaxis,:,:].to(device)))))\n",
    "                deno = torch.sqrt(torch.sum(torch.square(image[k,t_p,:,:][np.newaxis,np.newaxis,:,:])))\n",
    "                Loss_img = nume/deno\n",
    "                psnrValue = psnr(image_Predition[k,:,:,:][np.newaxis,:,:,:].cpu(), image[k,t_p,:,:][np.newaxis,np.newaxis,:,:].cpu())\n",
    "                ssimValue = ssim(image_Predition[k,:,:,:][np.newaxis,:,:,:].cpu(), image[k,t_p,:,:][np.newaxis,np.newaxis,:,:].cpu())\n",
    "                PSNR_V.append(psnrValue.item())\n",
    "                SSIM_V.append(ssimValue.item())\n",
    "                MSE_IMG_V.append(Loss_img.item())\n",
    "\n",
    "            if l==1:\n",
    "                imshow(vutils.make_grid(image_Predition.cpu(), padding=2, nrow=5, normalize=False), batch_size, 'fix_mask',cmap='gray')\n",
    "                imshow(vutils.make_grid(image[:,t_p,:,:][:,np.newaxis,:,:].cpu(), padding=2, nrow=5, normalize=False), batch_size, 'GroundTruth_mask',cmap='gray')\n",
    "                imshow(vutils.make_grid(torch.abs(image[:,t_p,:,:][:,np.newaxis,:,:].cpu()-image_Predition.cpu()), padding=2, nrow=5, normalize=False), batch_size, 'diff_pred_GT',cmap='jet')\n",
    "\n",
    "            \n",
    "            ##########################################################3\n",
    "            ## correct values of estimated image using true ones\n",
    "            Predition[:,0,:,:] = image_fft_r[:,t_p,:,:].to(device) * mask[t_p,:,:]\n",
    "            Predition[:,1,:,:] = image_fft_i[:,t_p,:,:].to(device) * mask[t_p,:,:]\n",
    "            \n",
    "            ## Calculate the Loss term\n",
    "            complexPrediction  = Predition[:,0,:,:][:,np.newaxis,:,:]+Predition[:,1,:,:][:,np.newaxis,:,:]*1j\n",
    "            complexPrediction = torch.fft.ifftshift(complexPrediction,dim=(2,3))\n",
    "            image_Predition = torch.fft.ifft2(complexPrediction)\n",
    "            image_Predition = torch.real(torch.tensor(image_Predition).float())\n",
    "\n",
    "            for k in range(image_Predition.shape[0]):\n",
    "                nume = torch.sqrt(torch.sum(torch.square((image_Predition[k,:,:,:][np.newaxis,:,:,:]-image[k,t_p,:,:][np.newaxis,np.newaxis,:,:].to(device)))))\n",
    "                deno = torch.sqrt(torch.sum(torch.square(image[k,t_p,:,:][np.newaxis,np.newaxis,:,:])))\n",
    "                Loss_img = nume/deno\n",
    "                psnrValue = psnr(image_Predition[k,:,:,:][np.newaxis,:,:,:].cpu(), image[k,t_p,:,:][np.newaxis,np.newaxis,:,:].cpu())\n",
    "                ssimValue = ssim(image_Predition[k,:,:,:][np.newaxis,:,:,:].cpu(), image[k,t_p,:,:][np.newaxis,np.newaxis,:,:].cpu())\n",
    "                PSNR_V2.append(psnrValue.item())\n",
    "                SSIM_V2.append(ssimValue.item())\n",
    "                MSE_IMG_V2.append(Loss_img.item())\n",
    "\n",
    "            if l==1:\n",
    "                imshow(vutils.make_grid(image_Predition.cpu(), padding=2, nrow=5, normalize=False), batch_size, 'fix_zerofill',cmap='gray')\n",
    "                imshow(vutils.make_grid(torch.abs(image[:,t_p,:,:][:,np.newaxis,:,:]-image_Predition).cpu(), padding=2, nrow=5, normalize=False), batch_size, 'diff_zerofill_GT',cmap='jet')\n",
    "\n",
    "                # imshow(vutils.make_grid(image[:,t_p,:,:][:,np.newaxis,:,:].cpu(), padding=2, nrow=5, normalize=True), batch_size, 'GroundTruth_zerofill')\n",
    "\n",
    "\n",
    "        mdic2 = {\"PSNR_ZF\": PSNR_V2,\"SSIM_ZF\": SSIM_V2,\"NMSE_ZF\": MSE_IMG_V2,\"PSNR_M\": PSNR_V,\"SSIM_M\": SSIM_V,\"NMSE_M\": MSE_IMG_V}\n",
    "        # print('LOG:')\n",
    "        # print(mdic2)\n",
    "        savemat(save_to_dir+\"LOG.mat\", mdic2)\n",
    "        with open(save_to_dir+\"LOG.json\", \"w\") as outfile:\n",
    "            json.dump(mdic2, outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6aa9b169",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "vscode": {
   "interpreter": {
    "hash": "dd42dc5079a55ff97ff57ff9b01ace7b918ee8431bba5bd199ac8f7faef5fc7a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
